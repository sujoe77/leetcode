Different cache implementation
    LRU cache on geekforgeeks (https://www.geeksforgeeks.org/lru-cache-implementation/)
        java cache api
        algo and data structure
            hashmap
            linkTable -> lock on node

        sync / async to maintain cache
        cache penetration (use option)
        blocking operations
        multi-thread


    example on jcip
        thread
        future

        problem we met, and solution
            hashmap loop -> concurrent hashmap
            Idempotence (duplicated transfer caused by john in cpg) -> use one thread / unique id
            copyOnWrite -> make a copy
            field with thread id -> avoid using threadid
            threadlocal, atomic, volatile
            retry pattern -> count down latches
            overwrite record -> optimistic locking
            replication problem -> aof
            no timeout on time consuming calls -> Future

        solution
            optimistic locking
            immutable, function programming, share nothing (confine to 1 thread, nonblocking and lock-free)

    distributed cache
        partition
            consistent hashing (virtual node, domino effect), see cache below
            avoid hot point -> https://arxiv.org/abs/1608.01350
            avoid avalanche: SPOCA stands for Stateless, Proportional, Optimally-Consistent Addressing.
                https://www.usenix.org/legacy/event/atc11/tech/final_files/Chawla.pdf

        replication
            3 types of replication
            configuration service, zookeeper



        


Goals
    Consistency
        thread safe
            visibility, atomicity
            pessimistic, optimistic

        ifAbsent
    availability
    performance
        latency
        throughput
        scalability
        
    

Future    
    make time window as small as possible
    
    use case
        deal with latency
        async, timeout, avoid waiting forever
        thread pool

    FutureTask implementation
        volatile and atomic
        thread local (pitfall)

Concurrent collection
    3 types of collection
        not thread safe
        synchronized collection - vector, hashtable, performance problem
        concurrent collection - vs normal collection version
            my notes
            implementation

    immutability
        immutable collections, implementation

    problem met
        hashmap implementation
        thread safe delegation - not make object inside thread safe

cache
    eviction
    penetration
    cache expiration
    http://appdianping.com/2019/03/27/how-to-solve-the-five-difficulties-of-redis-avalanche-penetration-and-concurrent/

Euler formula
JVM structure
CPU architecture
Redis
CAP
    
states of thread

3 levels of concurrency
    1 core, 1 thread
    multi-computer, many thread


Zookeeper


Ref:
    code: https://www.geeksforgeeks.org/lru-cache-implementation/
    youtube - system design interview - cache
    java doc - future and collection impl.
    
    Paper:
        SPOCA: https://www.usenix.org/legacy/event/atc11/tech/final_files/Chawla.pdf
        Bounded load: https://arxiv.org/abs/1608.01350
        ZooKeeper: Wait-free coordination for Internet-scale systems
            https://www.usenix.org/legacy/event/atc10/tech/full_papers/Hunt.pdf

    Books:
        jcip
        7 models of concurrency
        redis book, document

    Latency: 
        http://highscalability.com/blog/2009/7/25/latency-is-everywhere-and-it-costs-you-sales-how-to-crush-it.html

     http://appdianping.com/2019/03/27/how-to-solve-the-five-difficulties-of-redis-avalanche-penetration-and-concurrent/

     Consistent hashing
        https://medium.com/@dgryski/consistent-hashing-algorithmic-tradeoffs-ef6b8e2fcae8
        https://medium.com/vimeo-engineering-blog/improving-load-balancing-with-a-new-consistent-hashing-algorithm-9f1bd75709ed

    
